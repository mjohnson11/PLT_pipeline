{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") # so many settingwithcopywarnings..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing BFA files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbfa2 = pd.read_csv('../BFA_data/Combined_Counts/dBFA2_counts_with_env_info.csv')\n",
    "hbfa1 = pd.read_csv('../BFA_data/Combined_Counts/hBFA1_counts_with_env_info.csv')\n",
    "hbfa2 = pd.read_csv('../BFA_data/Combined_Counts/hBFA2_counts_with_env_info.csv')\n",
    "nd = {'dBFA2': dbfa2, 'hBFA1': hbfa1, 'hBFA2': hbfa2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading timepoint exclusion info from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example defaultdict(<class 'list'>, {'R2': ['16']})\n"
     ]
    }
   ],
   "source": [
    "tp_exclusion = pd.read_excel('accessory_files/tp_exclusion_list.xlsx', sheet_name='exclusion_list')\n",
    "tp_ex = defaultdict(lambda: defaultdict(lambda: defaultdict(list))) # dict like tp_ex[bfa_name][env_name][replicate] = list of excluded tps\n",
    "for row in np.array(tp_exclusion[['ASSAY', 'ENV', 'REP', 'TIME']]):\n",
    "    tp_ex[row[0]][row[1]][row[2]] = str(row[3]).split(';')\n",
    "print('Example', tp_ex['hBFA1']['FLC4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High AT exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_complement(seq):\n",
    "    \"\"\"reverse complements a dna sequence (does not convert any non-atcg/ATCG characters)\"\"\"\n",
    "    watson_crick = {'A': 'T', 'T': 'A', 'G': 'C', 'C': 'G', 'a': 't', 't': 'a', 'g': 'c', 'c': 'g'}\n",
    "    return ''.join([watson_crick.setdefault(c, c) for c in seq[::-1]])\n",
    "\n",
    "# including the sequence between the barcodes to get the max AT run of the whole region (which is flanked by CG seqs)\n",
    "middle_seq = 'ATAACTTCGTATAATGTATGCTATACGAAGTTAT'\n",
    "\n",
    "def gc(s):\n",
    "    return len([i for i in s if i in ['G', 'C']])\n",
    "    \n",
    "def sliding_window_min(row, win_size):\n",
    "    s = row['Diverse.BC'] + middle_seq + reverse_complement(row['Environment.BC'])\n",
    "    return min([gc(s[i:i+win_size]) for i in range(len(s)-win_size+1)])\n",
    "\n",
    "for b in nd:\n",
    "    # also doing some renaming here\n",
    "    nd[b] = nd[b][nd[b].apply(lambda r: sliding_window_min(r, 26)>4, axis=1)].rename(columns = {'Full.BC': 'Barcode', 'Subpool.Environment': 'Home_Environment'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hBFA1 242\n",
      "hBFA2 298\n",
      "dBFA2 91\n"
     ]
    }
   ],
   "source": [
    "# Getting putative neutral classes\n",
    "putative_neuts = dict()\n",
    "putative_neuts['hBFA1'] = list(nd['hBFA1'].loc[nd['hBFA1']['Home_Environment'] == 'YPD_alpha']['Barcode'])\n",
    "putative_neuts['hBFA2'] = list(nd['hBFA2'].loc[nd['hBFA2']['Home_Environment'] == 'CLM_2N']['Barcode'])\n",
    "putative_neuts['dBFA2'] = list(nd['dBFA2'].loc[nd['dBFA2']['Home_Environment'] == 'Ancestor_YPD_2N'].loc[nd['dBFA2']['Which.Subpools'] == '-R1-1']['Barcode'])\n",
    "\n",
    "for n in putative_neuts:\n",
    "    print(n, len(putative_neuts[n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple s measuring code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple s measurement functions\n",
    "def calc_interval_logslope(row, t1, t2, time1, time2, sum1, sum2, read_cutoff, gens_per_day):\n",
    "    # simply calculates the slope of log(freq) if boths tps have >=read_cutoff reads (else returns nan)\n",
    "    if row[t1] < read_cutoff or row[t2] < read_cutoff:\n",
    "        return np.nan\n",
    "    else:\n",
    "        logdif = np.log(row[t2]/sum2) - np.log(row[t1]/sum1)\n",
    "        return logdif / (gens_per_day*(time2-time1))\n",
    "\n",
    "def get_s_rec(row, tps, read_cutoff):\n",
    "    # returns a list of s values from different time intervals for this barcode\n",
    "    use_tps = [i for i in tps if row[i] >= read_cutoff]\n",
    "    return [row['scaled.s_' + str(use_tps[i]) + '_' + str(use_tps[i+1])] for i in range(len(use_tps)-1)]\n",
    "\n",
    "def get_neut_fit(neut_data, t1, t2, time1, time2, sum1, sum2, read_cutoff, gens_per_day):\n",
    "    # checking if we have enough counts to just use the median log slope (almost always the case)\n",
    "    usable = neut_data[(neut_data[t1] >= read_cutoff) & (neut_data[t2] >= read_cutoff)]\n",
    "    if len(usable) >= 10:\n",
    "        return np.nanmedian(neut_data['s_' + t1 + '_' + t2])\n",
    "    # combining lineages until we get enough counts to measure neutral fitness (just needed for CLM and FLC)\n",
    "    # sorting to shuffle barcodes haphazardly\n",
    "    #print('ok', t1, t2, neut_data[[t1, t2]])\n",
    "    neut_data = neut_data.sort_values('Barcode')\n",
    "    # First step, combining to get only 20 barcodes:\n",
    "    neut_data['grouper'] = [i//(len(neut_data)/20) for i in range(len(neut_data))]\n",
    "    neut_data = neut_data[['grouper', t1, t2]].groupby('grouper').sum().reset_index()\n",
    "    # Now keep combining two by two until we get at least 3 barcodes with the minimum read number\n",
    "    while len(neut_data[(neut_data[t1] >= read_cutoff) & (neut_data[t2] >= read_cutoff)]) < 3:\n",
    "        neut_data['grouper'] = [i//2 for i in range(len(neut_data))] # combine 2 barcodes together\n",
    "        neut_data = neut_data[['grouper', t1, t2]].groupby('grouper').sum().reset_index()\n",
    "        if len(neut_data) < 3:\n",
    "            #print('akk', neut_data)\n",
    "            return np.nan\n",
    "    usable = neut_data[(neut_data[t1] >= read_cutoff) & (neut_data[t2] >= read_cutoff)]\n",
    "    #print('oh', len(usable), usable[[t1, t2]])\n",
    "    return np.nanmedian([calc_interval_logslope(r, t1, t2, time1, time2, sum1, sum2, read_cutoff, gens_per_day) for jnk, r in usable.iterrows()])\n",
    "    \n",
    "\n",
    "def simple_s_measuring(td, tps, times, neut_bcs, neut_reference_read_cutoff, gens_per_day, read_cutoff=10):\n",
    "    # calculates log-slopes for all lineages for all possible time intervals, scales by the median log-slope of the neutral class and then for\n",
    "    # each lineages, using all timepoints with at least read_cutoff reads, averages the consecutive time interval scaled s values to get a lineage s ('s'). \n",
    "    # Also records the number of intervals used ('len.s'), and the standard error of the different measures ('stderr.s')\n",
    "    td['Total.Reads'] = np.sum(td[[t for t in tps]], axis=1)\n",
    "    for i in range(len(tps)-1):\n",
    "        for j in range(i+1, len(tps)):\n",
    "            s1 = sum(td[tps[i]])\n",
    "            s2 = sum(td[tps[j]])\n",
    "            td['s_' + str(tps[i]) + '_' + str(tps[j])] = td.apply(lambda r: calc_interval_logslope(r, tps[i], tps[j], times[i], times[j], s1, s2, read_cutoff, gens_per_day), axis=1)\n",
    "            neut_data = td[(td['Barcode'].isin(neut_bcs)) & (td['Total.Reads'] > neut_reference_read_cutoff)]\n",
    "            median_neut_fit = get_neut_fit(neut_data, tps[i], tps[j], times[i], times[j], s1, s2, read_cutoff, gens_per_day)\n",
    "            #median_neut_fit = np.nanmedian(td[(td['Barcode'].isin(neut_bcs)) & (td['Total.Reads'] > neut_reference_read_cutoff)]['s_' + str(tps[i]) + '_' + str(tps[j])])\n",
    "            td['scaled.s_' + str(tps[i]) + '_' + str(tps[j])] = td['s_' + str(tps[i]) + '_' + str(tps[j])] - median_neut_fit\n",
    "    # calling get_s_rec 3 times is silly but hey I'm doing it...\n",
    "    td['s'] = td.apply(lambda r: np.nanmean(get_s_rec(r, tps, read_cutoff)), axis=1) # mean s across timepoint intervals\n",
    "    td['len.s'] = td.apply(lambda r: len([s for s in get_s_rec(r, tps, read_cutoff) if not np.isnan(s)]), axis=1) # this is number of timepoint intervals\n",
    "    td['stderr.s'] = td.apply(lambda r: np.nanstd(get_s_rec(r, tps, read_cutoff))/np.sqrt(r['len.s']), axis=1) # this is stderr across timepoint intervals\n",
    "    return td[['Barcode', 's', 'len.s', 'stderr.s']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dBFA2 YPD\n",
      "dBFA2 SC\n",
      "dBFA2 37C\n",
      "dBFA2 pH3_8\n",
      "dBFA2 pH7_3\n",
      "dBFA2 21C\n",
      "dBFA2 GlyEtOH\n",
      "dBFA2 FLC4\n",
      "dBFA2 CLM\n",
      "dBFA2 02M_NaCl\n",
      "hBFA1 YPD\n",
      "hBFA1 SC\n",
      "hBFA1 37C\n",
      "hBFA1 pH3_8\n",
      "hBFA1 pH7_3\n",
      "hBFA1 21C\n",
      "hBFA1 GlyEtOH\n",
      "hBFA1 FLC4\n",
      "hBFA1 CLM\n",
      "hBFA1 02M_NaCl\n",
      "hBFA2 YPD\n",
      "hBFA2 SC\n",
      "hBFA2 37C\n",
      "hBFA2 pH3_8\n",
      "hBFA2 pH7_3\n",
      "hBFA2 21C\n",
      "hBFA2 GlyEtOH\n",
      "hBFA2 FLC4\n",
      "hBFA2 CLM\n",
      "hBFA2 02M_NaCl\n"
     ]
    }
   ],
   "source": [
    "envs_use = ['YPD', 'SC', '37C', 'pH3_8', 'pH7_3', '21C', 'GlyEtOH', 'FLC4', 'CLM', '02M_NaCl']\n",
    "home_envs_use = [e+'_alpha' for e in envs_use] + [e+'_2N' for e in envs_use] + ['Ancestor_YPD_2N']\n",
    "\n",
    "simple_fit_data = defaultdict(dict)\n",
    "c_times = [1, 2, 3, 4, 5]\n",
    "for bfa_name in nd:\n",
    "    td = nd[bfa_name][nd[bfa_name]['Home_Environment'].isin(home_envs_use)]\n",
    "    bcs = list(td['Barcode'])\n",
    "    for env in envs_use:\n",
    "        print(bfa_name, env)\n",
    "        simple_fit_data[bfa_name][env] = dict()\n",
    "        reps = sorted(set([i.split('-')[2] for i in td.columns if 'Time' in i and env in i]))\n",
    "        for rep in reps:\n",
    "            if not 'EXCLUDE ALL' in tp_ex[bfa_name][env][rep]:\n",
    "                excluded_tps = tp_ex[bfa_name][env][rep]\n",
    "                tps = [bfa_name + '-' + env + '-' + rep + '-Time' + str(i*8) for i in c_times]\n",
    "                # to exclude timepoints I will just zero out the counts so they will be caught by the low coverage thresh\n",
    "                for tp in tps:\n",
    "                    if tp[tp.index('Time')+4:] in excluded_tps or tp not in td: # also fill in zeros if this tp is not in the data (eg tp 4 not sequenced in hBFA1)\n",
    "                        td[tp] = np.zeros(len(td))\n",
    "                included_tps = [t for t in tps if np.sum(td[t]) > 5e4]\n",
    "                if len(included_tps) < 2:\n",
    "                    print(bfa_name, env, rep, 'not enough tps')\n",
    "                else:\n",
    "                    simple_fit_data[bfa_name][env][rep] = simple_s_measuring(td, tps, c_times, putative_neuts[bfa_name], 30, 8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What data do I want?\n",
    "\n",
    "### For each BFA in each env:\n",
    "* 1 csv like: Barcode, Test_Environment, Home_Environment, Putative_Neutral, s_R1, s_R2, s_R3, s_ave, sM_R1, sM_R2, sM_R3, sM_ave\n",
    "* another like: Barcode, Test_Environment, Home_Environment, Putative_Neutral, Replicate, Time, Freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverseVarAve_w_nan(meanVals,standardDevs):\n",
    "    \"\"\"\n",
    "    from https://github.com/barcoding-bfa/fitness-assay-python\n",
    "    inverseVarAve - take weighted average with inverse variances.\n",
    "    :param meanVals: Values to be averaged, N x q. Averaged across second dimension\n",
    "    :param standardDevs: Standard errors of each value, N x q\n",
    "    :return weightedMeans: N x 1 vector of weighted average\n",
    "    :return weightedStandardDevs: N x 1 vector of final standard error\n",
    "    \"\"\"\n",
    "    weightedMeans = np.nansum(meanVals*np.power(standardDevs,-2),axis=1)/np.nansum(np.power(standardDevs,-2),axis=1)\n",
    "    weightedStandardDevs = np.power(np.nansum(np.power(standardDevs,-2),axis=1),-0.5)\n",
    "    return weightedMeans, weightedStandardDevs\n",
    "\n",
    "def get_max_error(errors):\n",
    "    # see comment below - this is to deal with std errs of 0 when there is only one measurement\n",
    "    if len([i for i in errors if i==0 or pd.isnull(i)])==len(errors):\n",
    "        return 1\n",
    "    else:\n",
    "        return np.nanmax(errors)\n",
    "\n",
    "fitd = dict()\n",
    "freqd = dict()\n",
    "bfa_reps = {'hBFA1': ['R1', 'R2'], 'hBFA2': ['R1', 'R2', 'R3'], 'dBFA2': ['R1', 'R2', 'R3']}\n",
    "key_cols = ['Barcode', 'Test_Environment', 'Home_Environment', 'Putative_Neutral']\n",
    "for bfa_name in nd:\n",
    "    fit_dats = []\n",
    "    freq_dats = []\n",
    "    for env in simple_fit_data[bfa_name]:\n",
    "        freq_dat = nd[bfa_name][nd[bfa_name]['Home_Environment'].isin(home_envs_use)]\n",
    "        freq_dat['Putative_Neutral'] = freq_dat['Barcode'].isin(putative_neuts[bfa_name])\n",
    "        freq_dat['Test_Environment'] = [env]*len(freq_dat)\n",
    "        td = freq_dat[key_cols]\n",
    "        for rep in bfa_reps[bfa_name]:\n",
    "            if rep in simple_fit_data[bfa_name][env]:\n",
    "                b2s = {i[0]:i[1:] for i in np.array(simple_fit_data[bfa_name][env][rep][['Barcode', 's', 'stderr.s']])}\n",
    "                td['s_'+rep] = td['Barcode'].apply(lambda b: b2s[b][0])\n",
    "                td['s_'+rep+'_error'] = td['Barcode'].apply(lambda b: b2s[b][1])\n",
    "            else:\n",
    "                nanner = [np.nan]*len(td)\n",
    "                td['s_'+rep], td['s_'+rep+'_error'] = (nanner, nanner)\n",
    "                \n",
    "            excluded_tps = tp_ex[bfa_name][env][rep]\n",
    "            tps = [bfa_name + '-' + env + '-' + rep + '-Time' + str(i*8) for i in c_times]\n",
    "            tps_use = {tp:int(tp[tp.index('Time')+4:]) for tp in tps if tp[tp.index('Time')+4:] not in excluded_tps and tp in freq_dat}\n",
    "            for tp in tps_use:\n",
    "                freq_dat[tps_use[tp]] = np.clip(np.log10(freq_dat[tp]/np.sum(freq_dat[tp])), -6, 0)\n",
    "            \n",
    "            ttd = freq_dat[key_cols+list(tps_use.values())].melt(id_vars=key_cols, var_name='Time', value_name='Clipped_Log10(Freq)')\n",
    "            ttd['Replicate'] = [rep]*len(ttd)\n",
    "            freq_dats.append(ttd)\n",
    "        s_aves = np.array(td[['s_'+r for r in bfa_reps[bfa_name]]])\n",
    "        # In some cases, measurements had only one time interval, so they didn't have an error (std err is 0)\n",
    "        # in these cases, I will set the error to the max error for the other replicates (and 1 if none of the reps have standard errors)\n",
    "        error_cols = ['s_'+r+'_error' for r in bfa_reps[bfa_name]]\n",
    "        td['error_max'] = td.apply(lambda row: get_max_error([row[i] for i in error_cols]), axis=1)\n",
    "        for i in error_cols:\n",
    "            td[i] = td.apply(lambda row: np.max([row['error_max'], row[i]]), axis=1)\n",
    "        s_errs = np.array(td[error_cols])\n",
    "        td['s_iva'], td['s_iva_err'] = inverseVarAve_w_nan(s_aves, s_errs)\n",
    "        fit_dats.append(td[[i for i in td if i!='error_max']])\n",
    "    fitd[bfa_name] = pd.concat(fit_dats)\n",
    "    freqd[bfa_name] = pd.concat(freq_dats)\n",
    "    fitd[bfa_name].to_csv('Final_data_sets/'+bfa_name+'_all_fitness.csv', index=False)\n",
    "    freqd[bfa_name].to_csv('Final_data_sets/'+bfa_name+'_all_freqs_tidy.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BFA</th>\n",
       "      <th>Barcode</th>\n",
       "      <th>Home_Environment</th>\n",
       "      <th>ploidy</th>\n",
       "      <th>Putative_Neutral</th>\n",
       "      <th>Test_Environment</th>\n",
       "      <th>s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hBFA1</td>\n",
       "      <td>CGCACAAGAAAGAATAATCTTGAATTGGTAAAACCAGATTTGGCAT...</td>\n",
       "      <td>GlyEtOH_alpha</td>\n",
       "      <td>alpha</td>\n",
       "      <td>False</td>\n",
       "      <td>YPD</td>\n",
       "      <td>0.071075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hBFA1</td>\n",
       "      <td>AATAAAAGAAGGAAAAGCATTTAAACAAACAAACTTTCTTTTTTCT...</td>\n",
       "      <td>YPD_alpha</td>\n",
       "      <td>alpha</td>\n",
       "      <td>True</td>\n",
       "      <td>YPD</td>\n",
       "      <td>0.093827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hBFA1</td>\n",
       "      <td>ATTAAAAAATGAAAGTCTGTTCAATGGAATCAATCAAGTTTCTGTT...</td>\n",
       "      <td>FLC4_alpha</td>\n",
       "      <td>alpha</td>\n",
       "      <td>False</td>\n",
       "      <td>YPD</td>\n",
       "      <td>0.055776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hBFA1</td>\n",
       "      <td>TGTATAAAGTAGAAAGAGTTTCACTGAGGAGAACGGGGTTGGGGGT...</td>\n",
       "      <td>GlyEtOH_alpha</td>\n",
       "      <td>alpha</td>\n",
       "      <td>False</td>\n",
       "      <td>YPD</td>\n",
       "      <td>0.062370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hBFA1</td>\n",
       "      <td>CGATGAAAGGGAAAATGAATTAACAGTTCCCAAGCGAATTATATTT...</td>\n",
       "      <td>CLM_alpha</td>\n",
       "      <td>alpha</td>\n",
       "      <td>False</td>\n",
       "      <td>YPD</td>\n",
       "      <td>-0.005730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5856</th>\n",
       "      <td>dBFA2</td>\n",
       "      <td>TTTGCAAACGAGAATGTCTTTCTAAGTTATCAAACTTGTTTTTCGT...</td>\n",
       "      <td>21C_2N</td>\n",
       "      <td>2N</td>\n",
       "      <td>False</td>\n",
       "      <td>02M_NaCl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5858</th>\n",
       "      <td>dBFA2</td>\n",
       "      <td>CCATTAACCGGTAAAAACGTTTGTATAAGGTAATAGAGTTTTTCTT...</td>\n",
       "      <td>pH7_3_2N</td>\n",
       "      <td>2N</td>\n",
       "      <td>False</td>\n",
       "      <td>02M_NaCl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5860</th>\n",
       "      <td>dBFA2</td>\n",
       "      <td>CTCAAAATAATAAAACGAGTTTCATCGTGTCAATCGATTTTTTTGT...</td>\n",
       "      <td>02M_NaCl_2N</td>\n",
       "      <td>2N</td>\n",
       "      <td>False</td>\n",
       "      <td>02M_NaCl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5862</th>\n",
       "      <td>dBFA2</td>\n",
       "      <td>ATAATAACTGACAAATCCTTTCACTCTACCCAACGAAATTGTGTTT...</td>\n",
       "      <td>02M_NaCl_2N</td>\n",
       "      <td>2N</td>\n",
       "      <td>False</td>\n",
       "      <td>02M_NaCl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>dBFA2</td>\n",
       "      <td>TTATAAAAGCTAAACTGATTTGGAAACCATGAAAATCGTTTATAAT...</td>\n",
       "      <td>pH7_3_2N</td>\n",
       "      <td>2N</td>\n",
       "      <td>False</td>\n",
       "      <td>02M_NaCl</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83690 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        BFA                                            Barcode  \\\n",
       "2     hBFA1  CGCACAAGAAAGAATAATCTTGAATTGGTAAAACCAGATTTGGCAT...   \n",
       "4     hBFA1  AATAAAAGAAGGAAAAGCATTTAAACAAACAAACTTTCTTTTTTCT...   \n",
       "5     hBFA1  ATTAAAAAATGAAAGTCTGTTCAATGGAATCAATCAAGTTTCTGTT...   \n",
       "6     hBFA1  TGTATAAAGTAGAAAGAGTTTCACTGAGGAGAACGGGGTTGGGGGT...   \n",
       "7     hBFA1  CGATGAAAGGGAAAATGAATTAACAGTTCCCAAGCGAATTATATTT...   \n",
       "...     ...                                                ...   \n",
       "5856  dBFA2  TTTGCAAACGAGAATGTCTTTCTAAGTTATCAAACTTGTTTTTCGT...   \n",
       "5858  dBFA2  CCATTAACCGGTAAAAACGTTTGTATAAGGTAATAGAGTTTTTCTT...   \n",
       "5860  dBFA2  CTCAAAATAATAAAACGAGTTTCATCGTGTCAATCGATTTTTTTGT...   \n",
       "5862  dBFA2  ATAATAACTGACAAATCCTTTCACTCTACCCAACGAAATTGTGTTT...   \n",
       "5864  dBFA2  TTATAAAAGCTAAACTGATTTGGAAACCATGAAAATCGTTTATAAT...   \n",
       "\n",
       "     Home_Environment ploidy  Putative_Neutral Test_Environment         s  \n",
       "2       GlyEtOH_alpha  alpha             False              YPD  0.071075  \n",
       "4           YPD_alpha  alpha              True              YPD  0.093827  \n",
       "5          FLC4_alpha  alpha             False              YPD  0.055776  \n",
       "6       GlyEtOH_alpha  alpha             False              YPD  0.062370  \n",
       "7           CLM_alpha  alpha             False              YPD -0.005730  \n",
       "...               ...    ...               ...              ...       ...  \n",
       "5856           21C_2N     2N             False         02M_NaCl       NaN  \n",
       "5858         pH7_3_2N     2N             False         02M_NaCl       NaN  \n",
       "5860      02M_NaCl_2N     2N             False         02M_NaCl       NaN  \n",
       "5862      02M_NaCl_2N     2N             False         02M_NaCl       NaN  \n",
       "5864         pH7_3_2N     2N             False         02M_NaCl       NaN  \n",
       "\n",
       "[83690 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling haploid fitnesses measured in hBFA correctly\n",
    "# the reference class used in hBFA2 was CLM_2N, \n",
    "# so I will use the median YPD_alpha fitness in hBFA 2 to scale haploid fitnesses\n",
    "\n",
    "haploid_disadvantage = dict()\n",
    "td = fitd['hBFA2']\n",
    "for te in set(td['Test_Environment']):\n",
    "    haploid_disadvantage[te] = np.nanmedian(td[(td['Home_Environment']=='YPD_alpha') & (td['Test_Environment']==te)]['s_iva'])\n",
    "    \n",
    "haploid_disadvantage\n",
    "\n",
    "def fix_fitness(row):\n",
    "    # if this is a haploid strain in hBFA2, adjust the fitness to be scaled to the haploid ancestor\n",
    "    if row['BFA']=='hBFA2' and '_alpha' in row['Home_Environment']:\n",
    "        return row['s_iva'] - haploid_disadvantage[row['Test_Environment']]\n",
    "    else:\n",
    "        return row['s_iva']\n",
    "    \n",
    "def fix_put_neut(row):\n",
    "    if row['BFA'] == 'hBFA2' and row['ploidy'] == 'alpha':\n",
    "        return row['Home_Environment'] == 'YPD_alpha'\n",
    "    else:\n",
    "        return row['Putative_Neutral']\n",
    "        \n",
    "\n",
    "env_map = {'GlyEtOH': 'Glycerol/Ethanol', '37C': '37°C', 'pH7_3': 'pH 7.3', 'FLC4': 'Fluconazole', 'CLM': 'Clotrimazole',\n",
    "          '21C': '21°C', 'SC': 'SC', 'YPD': 'YPD', 'pH3_8': 'pH 3.8', '02M_NaCl': '02M NaCl'}\n",
    "fds = []\n",
    "bfas = ['hBFA1', 'hBFA2', 'dBFA2']\n",
    "for bfa in bfas:\n",
    "    tmp = fitd[bfa]\n",
    "    tmp['BFA'] = bfa\n",
    "    tmp['s'] = tmp.apply(fix_fitness, axis=1)\n",
    "    tmp['ploidy'] = tmp['Home_Environment'].str.split('_').str[-1]\n",
    "    tmp['Putative_Neutral'] = tmp.apply(fix_put_neut, axis=1)\n",
    "    fds.append(tmp[['BFA', 'Barcode', 'Home_Environment', 'ploidy', 'Putative_Neutral', 'Test_Environment', 's']])\n",
    "    \n",
    "fd = pd.concat(fds)\n",
    "fd.to_csv('Final_data_sets/All_fitness_tidy.csv', index=False)\n",
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "milo_py37",
   "language": "python",
   "name": "milo_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
